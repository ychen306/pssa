; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: %opt %s -S -passes=global-slp,jump-threading,simplifycfg -do-versioning | FileCheck %s
; ModuleID = 'yarpgen920.ll'
source_filename = "yarpgen920.ll"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx10.15.0"

define i8 @_Z1obPA1_A1_A1_i(ptr %p2, ptr %arrayidx6, i64 %idxprom7) #0 {
; CHECK-LABEL: @_Z1obPA1_A1_A1_i(
; CHECK-NEXT:  header:
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds [1 x i32], ptr [[ARRAYIDX6:%.*]], i64 0, i64 [[IDXPROM7:%.*]]
; CHECK:    br i1 [[TMP6:%.*]], label [[TMP25:%.*]], label [[TMP42:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    [[I14216:%.*]] = phi i8 [ 0, [[TMP25]] ], [ [[I14:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_6_VER_DEMOTED_0214:%.*]] = phi i8 [ [[TMP40:%.*]], [[TMP25]] ], [ [[CONV10_6_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_4_VER_DEMOTED_0158173212:%.*]] = phi i8 [ [[TMP38:%.*]], [[TMP25]] ], [ [[CONV10_4_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_2_VER_DEMOTED_0102117156175210:%.*]] = phi i8 [ [[TMP36:%.*]], [[TMP25]] ], [ [[CONV10_2_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_VER_DEMOTED_0425999119154177208:%.*]] = phi i8 [ [[TMP34:%.*]], [[TMP25]] ], [ [[CONV10_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_1_VER_DEMOTED_07288128147182205:%.*]] = phi i8 [ [[TMP35:%.*]], [[TMP25]] ], [ [[CONV10_1_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_3_VER_DEMOTED_0130145184203:%.*]] = phi i8 [ [[TMP37:%.*]], [[TMP25]] ], [ [[CONV10_3_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_5_VER_DEMOTED_0186201:%.*]] = phi i8 [ [[TMP39:%.*]], [[TMP25]] ], [ [[CONV10_5_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[CONV10_7_VER_DEMOTED_0:%.*]] = phi i8 [ [[TMP41:%.*]], [[TMP25]] ], [ [[CONV10_7_CLONE:%.*]], [[TMP42]] ]
; CHECK-NEXT:    [[I16:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_7_VER_DEMOTED_0]], i8 [[I14216]])
; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <8 x i8> undef, i8 [[CONV10_VER_DEMOTED_0425999119154177208]], i64 0
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <8 x i8> [[TMP7]], i8 [[CONV10_1_VER_DEMOTED_07288128147182205]], i64 1
; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <8 x i8> [[TMP8]], i8 [[CONV10_2_VER_DEMOTED_0102117156175210]], i64 2
; CHECK-NEXT:    [[TMP10:%.*]] = insertelement <8 x i8> [[TMP9]], i8 [[CONV10_3_VER_DEMOTED_0130145184203]], i64 3
; CHECK-NEXT:    [[TMP11:%.*]] = insertelement <8 x i8> [[TMP10]], i8 [[CONV10_4_VER_DEMOTED_0158173212]], i64 4
; CHECK-NEXT:    [[TMP12:%.*]] = insertelement <8 x i8> [[TMP11]], i8 [[CONV10_5_VER_DEMOTED_0186201]], i64 5
; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <8 x i8> [[TMP12]], i8 [[CONV10_6_VER_DEMOTED_0214]], i64 6
; CHECK-NEXT:    [[TMP14:%.*]] = insertelement <8 x i8> [[TMP13]], i8 [[CONV10_7_VER_DEMOTED_0]], i64 7
; CHECK-NEXT:    [[REDUCER_VEC:%.*]] = call <8 x i8> @llvm.umin.v8i8(<8 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <8 x i8> [[TMP14]])
; CHECK-NEXT:    [[TMP15:%.*]] = insertelement <8 x i8> undef, i8 [[CONV10_VER_DEMOTED_0425999119154177208]], i64 0
; CHECK-NEXT:    [[TMP16:%.*]] = insertelement <8 x i8> [[TMP15]], i8 [[CONV10_1_VER_DEMOTED_07288128147182205]], i64 1
; CHECK-NEXT:    [[TMP17:%.*]] = insertelement <8 x i8> [[TMP16]], i8 [[CONV10_2_VER_DEMOTED_0102117156175210]], i64 2
; CHECK-NEXT:    [[TMP18:%.*]] = insertelement <8 x i8> [[TMP17]], i8 [[CONV10_3_VER_DEMOTED_0130145184203]], i64 3
; CHECK-NEXT:    [[TMP19:%.*]] = insertelement <8 x i8> [[TMP18]], i8 [[CONV10_4_VER_DEMOTED_0158173212]], i64 4
; CHECK-NEXT:    [[TMP20:%.*]] = insertelement <8 x i8> [[TMP19]], i8 [[CONV10_5_VER_DEMOTED_0186201]], i64 5
; CHECK-NEXT:    [[TMP21:%.*]] = insertelement <8 x i8> [[TMP20]], i8 [[CONV10_6_VER_DEMOTED_0214]], i64 6
; CHECK-NEXT:    [[TMP22:%.*]] = insertelement <8 x i8> [[TMP21]], i8 [[CONV10_7_VER_DEMOTED_0]], i64 7
; CHECK-NEXT:    [[REDUCER_VEC7:%.*]] = call <8 x i8> @llvm.umin.v8i8(<8 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <8 x i8> [[TMP22]])
; CHECK-NEXT:    [[TMP23:%.*]] = call i8 @llvm.vector.reduce.umin.v8i8(<8 x i8> [[REDUCER_VEC]])
; CHECK-NEXT:    [[TMP24:%.*]] = call i8 @llvm.umin.i8(i8 0, i8 [[TMP23]])
; CHECK-NEXT:    ret i8 [[TMP24]]
; CHECK:       25:
; CHECK-NEXT:    store i8 0, ptr [[ARRAYIDX6]], align 1
; CHECK-NEXT:    [[TMP26:%.*]] = insertelement <8 x ptr> undef, ptr [[ARRAYIDX8]], i64 0
; CHECK-NEXT:    [[TMP27:%.*]] = insertelement <8 x ptr> [[TMP26]], ptr [[ARRAYIDX8]], i64 1
; CHECK-NEXT:    [[TMP28:%.*]] = insertelement <8 x ptr> [[TMP27]], ptr [[ARRAYIDX8]], i64 2
; CHECK-NEXT:    [[TMP29:%.*]] = insertelement <8 x ptr> [[TMP28]], ptr [[ARRAYIDX8]], i64 3
; CHECK-NEXT:    [[TMP30:%.*]] = insertelement <8 x ptr> [[TMP29]], ptr [[ARRAYIDX8]], i64 4
; CHECK-NEXT:    [[TMP31:%.*]] = insertelement <8 x ptr> [[TMP30]], ptr [[ARRAYIDX8]], i64 5
; CHECK-NEXT:    [[TMP32:%.*]] = insertelement <8 x ptr> [[TMP31]], ptr [[ARRAYIDX8]], i64 6
; CHECK-NEXT:    [[TMP33:%.*]] = insertelement <8 x ptr> [[TMP32]], ptr [[ARRAYIDX8]], i64 7
; CHECK-NEXT:    [[I3_VEC:%.*]] = call <8 x i32> @llvm.masked.gather.v8i32.v8p0(<8 x ptr> [[TMP33]], i32 4, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x i32> undef)
; CHECK-NEXT:    [[NEG_1_VEC:%.*]] = xor <8 x i32> [[I3_VEC]], zeroinitializer
; CHECK-NEXT:    [[CMP_I_I_I_1_VEC:%.*]] = icmp slt <8 x i32> [[NEG_1_VEC]], zeroinitializer
; CHECK-NEXT:    [[CONV10_1_VEC:%.*]] = zext <8 x i1> [[CMP_I_I_I_1_VEC]] to <8 x i8>
; CHECK-NEXT:    [[TMP34]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 0
; CHECK-NEXT:    [[TMP35]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 1
; CHECK-NEXT:    [[TMP36]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 2
; CHECK-NEXT:    [[TMP37]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 3
; CHECK-NEXT:    [[TMP38]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 4
; CHECK-NEXT:    [[TMP39]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 5
; CHECK-NEXT:    [[TMP40]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 6
; CHECK-NEXT:    [[TMP41]] = extractelement <8 x i8> [[CONV10_1_VEC]], i64 7
; CHECK-NEXT:    store i8 0, ptr [[P2:%.*]], align 1
; CHECK-NEXT:    br label [[EXIT:%.*]]
; CHECK:       42:
; CHECK-NEXT:    [[I1_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_CLONE:%.*]] = xor i32 [[I1_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_CLONE:%.*]] = icmp slt i32 [[NEG_CLONE]], 0
; CHECK-NEXT:    [[CONV10_CLONE]] = zext i1 [[CMP_I_I_I_CLONE]] to i8
; CHECK-NEXT:    [[I2:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_CLONE]], i8 0)
; CHECK-NEXT:    [[I3_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_1_CLONE:%.*]] = xor i32 [[I3_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_1_CLONE:%.*]] = icmp slt i32 [[NEG_1_CLONE]], 0
; CHECK-NEXT:    [[CONV10_1_CLONE]] = zext i1 [[CMP_I_I_I_1_CLONE]] to i8
; CHECK-NEXT:    [[I4:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_1_CLONE]], i8 [[I2]])
; CHECK-NEXT:    store i8 0, ptr [[ARRAYIDX6]], align 1
; CHECK-NEXT:    [[I5_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_2_CLONE:%.*]] = xor i32 [[I5_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_2_CLONE:%.*]] = icmp slt i32 [[NEG_2_CLONE]], 0
; CHECK-NEXT:    [[CONV10_2_CLONE]] = zext i1 [[CMP_I_I_I_2_CLONE]] to i8
; CHECK-NEXT:    [[I6:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_2_CLONE]], i8 [[I4]])
; CHECK-NEXT:    store i8 [[I2]], ptr [[P2]], align 1
; CHECK-NEXT:    [[I7_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_3_CLONE:%.*]] = xor i32 [[I7_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_3_CLONE:%.*]] = icmp slt i32 [[NEG_3_CLONE]], 0
; CHECK-NEXT:    [[CONV10_3_CLONE]] = zext i1 [[CMP_I_I_I_3_CLONE]] to i8
; CHECK-NEXT:    [[I8:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_3_CLONE]], i8 [[I6]])
; CHECK-NEXT:    [[I9_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_4_CLONE:%.*]] = xor i32 [[I9_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_4_CLONE:%.*]] = icmp slt i32 [[NEG_4_CLONE]], 0
; CHECK-NEXT:    [[CONV10_4_CLONE]] = zext i1 [[CMP_I_I_I_4_CLONE]] to i8
; CHECK-NEXT:    [[I10:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_4_CLONE]], i8 [[I8]])
; CHECK-NEXT:    [[I11_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_5_CLONE:%.*]] = xor i32 [[I11_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_5_CLONE:%.*]] = icmp slt i32 [[NEG_5_CLONE]], 0
; CHECK-NEXT:    [[CONV10_5_CLONE]] = zext i1 [[CMP_I_I_I_5_CLONE]] to i8
; CHECK-NEXT:    [[I12:%.*]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_5_CLONE]], i8 [[I10]])
; CHECK-NEXT:    [[I13_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_6_CLONE:%.*]] = xor i32 [[I13_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_6_CLONE:%.*]] = icmp slt i32 [[NEG_6_CLONE]], 0
; CHECK-NEXT:    [[CONV10_6_CLONE]] = zext i1 [[CMP_I_I_I_6_CLONE]] to i8
; CHECK-NEXT:    [[I14]] = tail call i8 @llvm.umin.i8(i8 [[CONV10_6_CLONE]], i8 [[I12]])
; CHECK-NEXT:    [[I15_CLONE:%.*]] = load i32, ptr [[ARRAYIDX8]], align 4
; CHECK-NEXT:    [[NEG_7_CLONE:%.*]] = xor i32 [[I15_CLONE]], 0
; CHECK-NEXT:    [[CMP_I_I_I_7_CLONE:%.*]] = icmp slt i32 [[NEG_7_CLONE]], 0
; CHECK-NEXT:    [[CONV10_7_CLONE]] = zext i1 [[CMP_I_I_I_7_CLONE]] to i8
; CHECK-NEXT:    br label [[EXIT]]
;
for.body.lr.ph:
  %arrayidx8 = getelementptr inbounds [1 x i32], ptr %arrayidx6, i64 0, i64 %idxprom7
  br label %for.body.lr.ph.new

for.body.lr.ph.new:                               ; preds = %for.body.lr.ph
  br label %for.body

for.cond.cleanup.loopexit.unr-lcssa.loopexit:     ; preds = %for.body
  %.unr.ph = phi i8 [ %i16, %for.body ]
  ret i8 %.unr.ph

for.body:                                         ; preds = %for.body, %for.body.lr.ph.new
  %i = phi i8 [ 0, %for.body.lr.ph.new ], [ %i16, %for.body ]
  %i1 = load i32, ptr %arrayidx8, align 4
  %neg = xor i32 %i1, 0
  %cmp.i.i.i = icmp slt i32 %neg, 0
  %conv10 = zext i1 %cmp.i.i.i to i8
  %i2 = tail call i8 @llvm.umin.i8(i8 %conv10, i8 %i)
  %i3 = load i32, ptr %arrayidx8, align 4
  %neg.1 = xor i32 %i3, 0
  %cmp.i.i.i.1 = icmp slt i32 %neg.1, 0
  %conv10.1 = zext i1 %cmp.i.i.i.1 to i8
  %i4 = tail call i8 @llvm.umin.i8(i8 %conv10.1, i8 %i2)
  store i8 0, ptr %arrayidx6, align 1
  %i5 = load i32, ptr %arrayidx8, align 4
  %neg.2 = xor i32 %i5, 0
  %cmp.i.i.i.2 = icmp slt i32 %neg.2, 0
  %conv10.2 = zext i1 %cmp.i.i.i.2 to i8
  %i6 = tail call i8 @llvm.umin.i8(i8 %conv10.2, i8 %i4)
  store i8 %i2, ptr %p2, align 1
  %i7 = load i32, ptr %arrayidx8, align 4
  %neg.3 = xor i32 %i7, 0
  %cmp.i.i.i.3 = icmp slt i32 %neg.3, 0
  %conv10.3 = zext i1 %cmp.i.i.i.3 to i8
  %i8 = tail call i8 @llvm.umin.i8(i8 %conv10.3, i8 %i6)
  %i9 = load i32, ptr %arrayidx8, align 4
  %neg.4 = xor i32 %i9, 0
  %cmp.i.i.i.4 = icmp slt i32 %neg.4, 0
  %conv10.4 = zext i1 %cmp.i.i.i.4 to i8
  %i10 = tail call i8 @llvm.umin.i8(i8 %conv10.4, i8 %i8)
  %i11 = load i32, ptr %arrayidx8, align 4
  %neg.5 = xor i32 %i11, 0
  %cmp.i.i.i.5 = icmp slt i32 %neg.5, 0
  %conv10.5 = zext i1 %cmp.i.i.i.5 to i8
  %i12 = tail call i8 @llvm.umin.i8(i8 %conv10.5, i8 %i10)
  %i13 = load i32, ptr %arrayidx8, align 4
  %neg.6 = xor i32 %i13, 0
  %cmp.i.i.i.6 = icmp slt i32 %neg.6, 0
  %conv10.6 = zext i1 %cmp.i.i.i.6 to i8
  %i14 = tail call i8 @llvm.umin.i8(i8 %conv10.6, i8 %i12)
  %i15 = load i32, ptr %arrayidx8, align 4
  %neg.7 = xor i32 %i15, 0
  %cmp.i.i.i.7 = icmp slt i32 %neg.7, 0
  %conv10.7 = zext i1 %cmp.i.i.i.7 to i8
  %i16 = tail call i8 @llvm.umin.i8(i8 %conv10.7, i8 %i14)
  br i1 false, label %for.body, label %for.cond.cleanup.loopexit.unr-lcssa.loopexit
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i8 @llvm.umin.i8(i8, i8) #1

attributes #0 = { "target-cpu"="penryn" }
attributes #1 = { nocallback nofree nosync nounwind readnone speculatable willreturn }
